{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc311c5",
   "metadata": {
    "papermill": {
     "duration": 0.00464,
     "end_time": "2025-03-08T10:47:11.324053",
     "exception": false,
     "start_time": "2025-03-08T10:47:11.319413",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "Here we are using emsemble models to help us predict who out of a list of passengers would be \"Transported\".\n",
    "\n",
    "Thank you to Nikhil R for his workbook, [here](https://www.kaggle.com/code/nikhilramlukan/spaceship-titanic/notebook). Which was the inspiration for my approach below.\n",
    "\n",
    "I took it one step further by doing Hyperparameter Tuning, Kfold cross validation. And having 2 models at the second layer to work with the predictions of the base layer models.\n",
    "\n",
    "I also added and changes some features in the preprocess_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "070dac4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:11.333815Z",
     "iopub.status.busy": "2025-03-08T10:47:11.333363Z",
     "iopub.status.idle": "2025-03-08T10:47:16.242379Z",
     "shell.execute_reply": "2025-03-08T10:47:16.241000Z"
    },
    "papermill": {
     "duration": 4.916755,
     "end_time": "2025-03-08T10:47:16.244777",
     "exception": false,
     "start_time": "2025-03-08T10:47:11.328022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636d2d5",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2025-03-08T10:47:16.252333",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.248819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9971ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.261720Z",
     "iopub.status.busy": "2025-03-08T10:47:16.261141Z",
     "iopub.status.idle": "2025-03-08T10:47:16.266840Z",
     "shell.execute_reply": "2025-03-08T10:47:16.265766Z"
    },
    "papermill": {
     "duration": 0.012956,
     "end_time": "2025-03-08T10:47:16.269005",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.256049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "    train_res = train.Transported.astype(int)\n",
    "    test_id = test.PassengerId\n",
    "    return train, test, train_res, test_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af912802",
   "metadata": {
    "papermill": {
     "duration": 0.003536,
     "end_time": "2025-03-08T10:47:16.276579",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.273043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c4c8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.285993Z",
     "iopub.status.busy": "2025-03-08T10:47:16.285262Z",
     "iopub.status.idle": "2025-03-08T10:47:16.300436Z",
     "shell.execute_reply": "2025-03-08T10:47:16.299408Z"
    },
    "papermill": {
     "duration": 0.022137,
     "end_time": "2025-03-08T10:47:16.302408",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.280271",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(train, test):\n",
    "    # Convert HomePlanet to categorical\n",
    "    train['HomePlanet'] = train['HomePlanet'].astype('category')\n",
    "    test['HomePlanet'] = test['HomePlanet'].astype('category')\n",
    "\n",
    "    # Handle missing values by adding \"Missing\" as a new category\n",
    "    train['HomePlanet'] = train['HomePlanet'].cat.add_categories('Missing').fillna('Missing')\n",
    "    test['HomePlanet'] = test['HomePlanet'].cat.add_categories('Missing').fillna('Missing')\n",
    "\n",
    "    # Convert Destination to categorical\n",
    "    train['Destination'] = train['Destination'].astype('category')\n",
    "    test['Destination'] = test['Destination'].astype('category')\n",
    "\n",
    "    # Handle missing values by adding \"Missing\" as a new category\n",
    "    train['Destination'] = train['Destination'].cat.add_categories('Missing').fillna('Missing')\n",
    "    test['Destination'] = test['Destination'].cat.add_categories('Missing').fillna('Missing')\n",
    "    \n",
    "    # Split Cabin\n",
    "    train[['Cabin_1', 'Cabin_2', 'Cabin_3']] = train['Cabin'].str.split('/', expand=True)\n",
    "    test[['Cabin_1', 'Cabin_2', 'Cabin_3']] = test['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "    # Convert Cabin_1 to categorical\n",
    "    train['Cabin_1'] = train['Cabin_1'].astype('category')\n",
    "    test['Cabin_1'] = test['Cabin_1'].astype('category')\n",
    "\n",
    "    # Handle missing values by adding \"Missing\" as a new category\n",
    "    train['Cabin_1'] = train['Cabin_1'].cat.add_categories('Missing').fillna('Missing')\n",
    "    test['Cabin_1'] = test['Cabin_1'].cat.add_categories('Missing').fillna('Missing')\n",
    "    \n",
    "    # Convert Cabin_3 to categorical\n",
    "    train['Cabin_3'] = train['Cabin_3'].astype('category')\n",
    "    test['Cabin_3'] = test['Cabin_3'].astype('category')\n",
    "    \n",
    "    # Handle missing values by adding \"Missing\" as a new category\n",
    "    train['Cabin_3'] = train['Cabin_3'].cat.add_categories('Missing').fillna('Missing')\n",
    "    test['Cabin_3'] = test['Cabin_3'].cat.add_categories('Missing').fillna('Missing')\n",
    "\n",
    "    cols = ['FoodCourt', 'RoomService', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for col in cols:\n",
    "        train[col] = train[col].fillna(0)\n",
    "        test[col] = test[col].fillna(0)\n",
    "\n",
    "    # Convert categorical features\n",
    "    categorical_columns = ['CryoSleep', 'VIP', 'HomePlanet', 'Destination', 'Cabin_1', 'Cabin_3']\n",
    "    for col in categorical_columns:\n",
    "        train[col] = train[col].astype('category')\n",
    "        test[col] = test[col].astype('category')\n",
    "\n",
    "        # Add 'Missing' category if it's not already present\n",
    "        if 'Missing' not in train[col].cat.categories:\n",
    "            train[col] = train[col].cat.add_categories('Missing')\n",
    "        if 'Missing' not in test[col].cat.categories:\n",
    "            test[col] = test[col].cat.add_categories('Missing')\n",
    "\n",
    "        # Now, fill NaN values with 'Missing'\n",
    "        train[col] = train[col].fillna('Missing')\n",
    "        test[col] = test[col].fillna('Missing')\n",
    "\n",
    "    # Advanced Feature Engineering\n",
    "    train['FamilySize'] = train['PassengerId'].apply(lambda x: int(x.split('_')[1]))\n",
    "    test['FamilySize'] = test['PassengerId'].apply(lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    train['Spending'] = train[cols].sum(axis=1)\n",
    "    test['Spending'] = test[cols].sum(axis=1)\n",
    "\n",
    "    # Calculate mean age, ignoring NaNs\n",
    "    mean_age = train['Age'].mean(skipna=True)\n",
    "    # Replace NaN with the mean age\n",
    "    train['Age'] = train['Age'].fillna(mean_age)\n",
    "    test['Age'] = test['Age'].fillna(mean_age)\n",
    "     \n",
    "    train.drop(['Name', 'Transported', 'PassengerId', 'Cabin', 'Cabin_2'], axis=1, inplace=True)\n",
    "    test.drop(['Name', 'PassengerId', 'Cabin', 'Cabin_2'], axis=1, inplace=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12109798",
   "metadata": {
    "papermill": {
     "duration": 0.003572,
     "end_time": "2025-03-08T10:47:16.309884",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.306312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f87838d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.319343Z",
     "iopub.status.busy": "2025-03-08T10:47:16.318579Z",
     "iopub.status.idle": "2025-03-08T10:47:16.327048Z",
     "shell.execute_reply": "2025-03-08T10:47:16.325966Z"
    },
    "papermill": {
     "duration": 0.01538,
     "end_time": "2025-03-08T10:47:16.329056",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.313676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_clustering(train, test):\n",
    "    # Select numerical features for clustering\n",
    "    features = ['Spending', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "    # Normalize only for those who spent money\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Separate train & test subsets where Spending > 0\n",
    "    spent_money_train = train[train['Spending'] > 0].copy()\n",
    "    spent_money_test = test[test['Spending'] > 0].copy()\n",
    "\n",
    "    # Apply scaling\n",
    "    spent_money_train[features] = scaler.fit_transform(spent_money_train[features])\n",
    "    spent_money_test[features] = scaler.transform(spent_money_test[features])  # Use same scaler as train!\n",
    "\n",
    "    # Apply K-Means clustering\n",
    "    k = 5  # You can experiment with different k values\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    spent_money_train['Cluster'] = kmeans.fit_predict(spent_money_train[features])\n",
    "    spent_money_test['Cluster'] = kmeans.predict(spent_money_test[features])  # Use trained k-means model!\n",
    "\n",
    "    # Initialize a new column with -1 for those who didn't spend money\n",
    "    train['SpendingCluster'] = -1\n",
    "    test['SpendingCluster'] = -1\n",
    "\n",
    "    # Assign cluster labels to those who spent money\n",
    "    train.loc[train['Spending'] > 0, 'SpendingCluster'] = spent_money_train['Cluster'].values\n",
    "    test.loc[test['Spending'] > 0, 'SpendingCluster'] = spent_money_test['Cluster'].values\n",
    "\n",
    "    train['SpendingCluster'] = train['SpendingCluster'].astype('category')\n",
    "    test['SpendingCluster'] = test['SpendingCluster'].astype('category')\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f441190",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2025-03-08T10:47:16.336413",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.332899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4110c91a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.345808Z",
     "iopub.status.busy": "2025-03-08T10:47:16.344868Z",
     "iopub.status.idle": "2025-03-08T10:47:16.351443Z",
     "shell.execute_reply": "2025-03-08T10:47:16.350378Z"
    },
    "papermill": {
     "duration": 0.013667,
     "end_time": "2025-03-08T10:47:16.353720",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.340053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tune_xgb(train, train_res):\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1],\n",
    "        'colsample_bytree': [0.8, 1]\n",
    "    }\n",
    "    xgb = XGBClassifier(eval_metric=\"logloss\", use_label_encoder=False, random_state=42, enable_categorical=True)\n",
    "    grid_search = GridSearchCV(xgb, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(train, train_res)\n",
    "    print(\"Best parameters for XGBoost:\", grid_search.best_params_)\n",
    "    return grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1f008c",
   "metadata": {
    "papermill": {
     "duration": 0.003536,
     "end_time": "2025-03-08T10:47:16.361177",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.357641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468850ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.370719Z",
     "iopub.status.busy": "2025-03-08T10:47:16.369931Z",
     "iopub.status.idle": "2025-03-08T10:47:16.378371Z",
     "shell.execute_reply": "2025-03-08T10:47:16.377172Z"
    },
    "papermill": {
     "duration": 0.015555,
     "end_time": "2025-03-08T10:47:16.380505",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.364950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_base_models(train, train_res):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    models = {\n",
    "        \"XGB\": tune_xgb(train, train_res),\n",
    "        \"LGB\": LGBMClassifier(random_state=42),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
    "    }\n",
    "    oof_preds = np.zeros((train.shape[0], len(models)))\n",
    "    \n",
    "    # List of categorical columns\n",
    "    cat_features = ['CryoSleep', 'VIP', 'HomePlanet', 'Destination', 'Cabin_1', 'Cabin_3', 'SpendingCluster']\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train, train_res)):\n",
    "        X_train, X_val = train.iloc[train_idx], train.iloc[val_idx]\n",
    "        y_train, y_val = train_res.iloc[train_idx], train_res.iloc[val_idx]\n",
    "        \n",
    "        for i, (name, model) in enumerate(models.items()):\n",
    "            if name == \"CatBoost\":\n",
    "                model.fit(X_train, y_train, cat_features=cat_features)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "            \n",
    "            oof_preds[val_idx, i] = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    return models, oof_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd49389",
   "metadata": {
    "papermill": {
     "duration": 0.003559,
     "end_time": "2025-03-08T10:47:16.388056",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.384497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train Meta Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bf946b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.398031Z",
     "iopub.status.busy": "2025-03-08T10:47:16.397046Z",
     "iopub.status.idle": "2025-03-08T10:47:16.404201Z",
     "shell.execute_reply": "2025-03-08T10:47:16.403064Z"
    },
    "papermill": {
     "duration": 0.014426,
     "end_time": "2025-03-08T10:47:16.406286",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.391860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_meta_models(oof_preds, train_res, train_columns):\n",
    "    oof_preds_df = pd.DataFrame(oof_preds, columns=[\"XGB\", \"LGB\", \"CatBoost\"])\n",
    "    meta_models = {\n",
    "        \"LogisticRegression\": LogisticRegression(),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    meta_model_scores = {}\n",
    "    for name, model in meta_models.items():\n",
    "        scores = cross_val_score(model, oof_preds_df, train_res, cv=5, scoring='accuracy')\n",
    "        meta_model_scores[name] = scores.mean()\n",
    "        print(f\"{name} CV Accuracy: {scores.mean():.4f}\")\n",
    "    \n",
    "    best_meta_model = max(meta_model_scores, key=meta_model_scores.get)\n",
    "    meta_models[best_meta_model].fit(oof_preds_df, train_res)\n",
    "    \n",
    "    return meta_models, best_meta_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b17725f",
   "metadata": {
    "papermill": {
     "duration": 0.003525,
     "end_time": "2025-03-08T10:47:16.413786",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.410261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3614f07c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.423711Z",
     "iopub.status.busy": "2025-03-08T10:47:16.422318Z",
     "iopub.status.idle": "2025-03-08T10:47:16.429351Z",
     "shell.execute_reply": "2025-03-08T10:47:16.428370Z"
    },
    "papermill": {
     "duration": 0.014297,
     "end_time": "2025-03-08T10:47:16.431764",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.417467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(models, meta_models, best_meta_model, test, test_id, train_columns):\n",
    "    # Ensure that test data has the same column names as the train data\n",
    "    test_preds = np.column_stack([models[name].predict_proba(test[train_columns])[:, 1] for name in models.keys()])\n",
    "    final_preds = meta_models[best_meta_model].predict(test_preds)\n",
    "    \n",
    "    submission = pd.DataFrame({'PassengerId': test_id, 'Transported': final_preds.astype(bool)})\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    print(\"Submission file saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db350f32",
   "metadata": {
    "papermill": {
     "duration": 0.003538,
     "end_time": "2025-03-08T10:47:16.439206",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.435668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "534f805b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T10:47:16.448965Z",
     "iopub.status.busy": "2025-03-08T10:47:16.447979Z",
     "iopub.status.idle": "2025-03-08T10:50:33.084891Z",
     "shell.execute_reply": "2025-03-08T10:50:33.081528Z"
    },
    "papermill": {
     "duration": 196.649073,
     "end_time": "2025-03-08T10:50:33.092038",
     "exception": false,
     "start_time": "2025-03-08T10:47:16.442965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters for XGBoost: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1656\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1656\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1655\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1657\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1656\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 15\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "LogisticRegression CV Accuracy: 0.8101\n",
      "RandomForest CV Accuracy: 0.7776\n",
      "Submission file saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, test, train_res, test_id = load_data(\"/kaggle/input/spaceship-titanic/train.csv\", \"/kaggle/input/spaceship-titanic/test.csv\")\n",
    "train, test = preprocess_data(train, test)\n",
    "train, test = apply_clustering(train, test)\n",
    "models, oof_preds = train_base_models(train, train_res)\n",
    "meta_models, best_meta_model = train_meta_models(oof_preds, train_res, train.columns)\n",
    "predict(models, meta_models, best_meta_model, test, test_id, train.columns)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3220602,
     "sourceId": 34377,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 205.675634,
   "end_time": "2025-03-08T10:50:33.926528",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-08T10:47:08.250894",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
